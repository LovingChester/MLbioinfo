{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone1_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PmalALktoyfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdfae514-f2ed-4449-bf23-8761d6bcd48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: sidechainnet in /usr/local/lib/python3.7/dist-packages (0.7.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sidechainnet) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from sidechainnet) (1.10.0+cu111)\n",
            "Requirement already satisfied: ProDy>=2.0 in /usr/local/lib/python3.7/dist-packages (from sidechainnet) (2.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sidechainnet) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sidechainnet) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from sidechainnet) (2.23.0)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (from sidechainnet) (1.79)\n",
            "Requirement already satisfied: py3Dmol in /usr/local/lib/python3.7/dist-packages (from sidechainnet) (1.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sidechainnet) (57.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from sidechainnet) (1.3.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ProDy>=2.0->sidechainnet) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->sidechainnet) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->sidechainnet) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->sidechainnet) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->sidechainnet) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->sidechainnet) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->sidechainnet) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->sidechainnet) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->sidechainnet) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install einops\n",
        "!pip install sidechainnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as du\n",
        "from torchvision import transforms as T\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch.utils import data\n",
        "import sidechainnet as scn\n",
        "import einops\n",
        "import gc\n",
        "from torch.utils.data import IterableDataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = f'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"using device: {device}\")"
      ],
      "metadata": {
        "id": "aNqYdBIXO4dO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b6f42c-dad0-47e0-b3ce-1f4002a1da5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load CASP7 data as pytorch tensors"
      ],
      "metadata": {
        "id": "4y2nE7MHrnEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = scn.load(casp_version=7, with_pytorch=\"dataloaders\", \n",
        "                seq_as_onehot=True, aggregate_model_input=False,\n",
        "               batch_size=16)"
      ],
      "metadata": {
        "id": "Sv1nWB2MromX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53fa1a9-f61b-4d9c-9195-7cfcaee439bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SidechainNet was loaded from ./sidechainnet_data/sidechainnet_casp7_30.pkl.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creates features for a batch of sequences"
      ],
      "metadata": {
        "id": "MJk1H1lO9Oa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_seq_features(batch):\n",
        "    '''\n",
        "    Take a batch of sequence info and return the sequence (one-hot),\n",
        "    evolutionary info and (phi, psi, omega) angles per position, \n",
        "    as well as position mask.\n",
        "    Also return the distance matrix, and distance mask.\n",
        "    '''\n",
        "    str_seqs = batch.str_seqs # seq in str format\n",
        "    seqs = batch.seqs # seq in one-hot format\n",
        "    int_seqs = batch.int_seqs # seq in int format\n",
        "    masks = batch.msks # which positions are valid\n",
        "    lengths = batch.lengths # seq length\n",
        "    evos = batch.evos # PSSM / evolutionary info\n",
        "    angs = batch.angs[:,:,0:2] # torsion angles: phi, psi\n",
        "    \n",
        "    # use coords to create distance matrix from c-beta\n",
        "    # except use c-alpha for G\n",
        "    # coords[:, 4, :] is c-beta, and coords[:, 1, :] is c-alpha\n",
        "    coords = batch.crds # seq coord info (all-atom)\n",
        "    batch_xyz = []\n",
        "    for i in range(coords.shape[0]):\n",
        "        xyz = []\n",
        "        xyz = [coords[i][cpos+4,:] \n",
        "                if masks[i][cpos//14] and str_seqs[i][cpos//14] != 'G'\n",
        "                else coords[i][cpos+1,:]\n",
        "                for cpos in range(0, coords[i].shape[0]-1, 14)]\n",
        "        batch_xyz.append(torch.stack(xyz))\n",
        "    batch_xyz = torch.stack(batch_xyz)\n",
        "    # now create pairwise distance matrix\n",
        "    dmats = torch.cdist(batch_xyz, batch_xyz)\n",
        "    # create matrix mask (0 means i,j invalid)\n",
        "    dmat_masks = torch.einsum('bi,bj->bij', masks, masks)\n",
        "    \n",
        "    return seqs, evos, angs, masks, dmats, dmat_masks"
      ],
      "metadata": {
        "id": "w9xYekTU9PU0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pair Representation"
      ],
      "metadata": {
        "id": "ks-xiGOvnl7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PairRep(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PairRep, self).__init__()\n",
        "\n",
        "        self.fcA = nn.Linear(20, 128)\n",
        "        self.fcB = nn.Linear(20, 128)\n",
        "    \n",
        "    def forward(self, seqs):\n",
        "        seq_len = seqs.size(dim=1)\n",
        "        A = self.fcA(seqs.to(torch.float))\n",
        "        B = self.fcB(seqs.to(torch.float))\n",
        "        As = A.repeat(seq_len, 1, 1, 1)\n",
        "        pair_rep = torch.transpose(As, 0, 1)\n",
        "        pair_rep = torch.transpose(pair_rep, 1, 2)\n",
        "\n",
        "        Bs = B.repeat(seq_len, 1, 1, 1)\n",
        "        pair_rep = pair_rep + torch.transpose(Bs, 0, 1)\n",
        "\n",
        "        return pair_rep"
      ],
      "metadata": {
        "id": "jqRe2sOGu4Pw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MSI resp"
      ],
      "metadata": {
        "id": "A7YdIX4-gClo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MSA(nn.Module):\n",
        "    def __init__(self, n_cluster):\n",
        "        super(MSA, self).__init__()\n",
        "\n",
        "        self.n_cluster = n_cluster\n",
        "        self.fcA = nn.Linear(21, 256)\n",
        "    \n",
        "    def forward(self, evos):\n",
        "        msa = self.fcA(evos)\n",
        "        msa = torch.unsqueeze(msa, dim=1)\n",
        "        msa = msa.repeat((1,self.n_cluster,1,1))\n",
        "\n",
        "        return msa"
      ],
      "metadata": {
        "id": "Pstpx3shp-AS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Row Attention"
      ],
      "metadata": {
        "id": "bBoJi_ri6uou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RowAttention(nn.Module):\n",
        "    '''Self Attention'''\n",
        "\n",
        "    def __init__(self, d, dk,num_heads):\n",
        "        '''define WQ, WK, WV projection matrices:\n",
        "        d: d_model is the original model dimension\n",
        "        dk: projection dimension for query, keys and values\n",
        "        '''\n",
        "        super(RowAttention, self).__init__()\n",
        "        \n",
        "        self.d = d  # d_model\n",
        "        self.dk = dk  # d_k: projection dimension\n",
        "        self.B_map = nn.Linear(128,1, bias=False)\n",
        "        self.G_map = nn.Linear(256,1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.num_heads = num_heads  # number of attention heads\n",
        "        self.WQ = nn.Linear(self.d, self.dk * self.num_heads, bias=False)\n",
        "        self.WK = nn.Linear(self.d, self.dk * self.num_heads, bias=False)\n",
        "        self.WV = nn.Linear(self.d, self.dk * self.num_heads, bias=False)\n",
        "        self.WO = nn.Linear(self.dk * self.num_heads, self.d, bias=False)\n",
        "\n",
        "    def forward(self, msa_rep, pair_rep):\n",
        "        '''project the context onto key, query and value spaces and\n",
        "        return the final value vectors\n",
        "        '''\n",
        "        #print(msa_rep.shape) # batch, cluter, seq, msa=256 \n",
        "        #print(pair_rep.shape) # b,c, seq, z= 128\n",
        "        \n",
        "        # calculate b first\n",
        "        B = self.B_map(pair_rep).squeeze(3).unsqueeze(1).unsqueeze(1) # b,1,1,seq,seq\n",
        "        Gate = self.G_map(msa_rep)\n",
        "        Gate = self.sigmoid(Gate).unsqueeze(2) # b,1,1,gate,seq\n",
        "\n",
        "        # input shape: (batch_size, block_size, d)\n",
        "        # let batch_size=b, block_size=l, num_heads=h\n",
        "        Q = self.WQ(msa_rep)  # shape: b, c, seq, dk\n",
        "        K = self.WK(msa_rep)  # shape: b, c, seq, dk\n",
        "        V = self.WV(msa_rep)  # shape: b, c, seq, dk\n",
        "\n",
        "        # split Q, K, V into heads and dk, move heads up front; KT is transpose of K\n",
        "        Q = einops.rearrange(\n",
        "            Q, 'b c s (h dk)-> b c h s dk', h=self.num_heads\n",
        "        )  # size: (b c h s dk)\n",
        "        KT = einops.rearrange(\n",
        "            K, 'b c s (h dk)-> b c h dk s', h=self.num_heads\n",
        "        )  # size: (b c h dk s)\n",
        "        V = einops.rearrange(\n",
        "            V, 'b c s (h dk)-> b c h s dk', h=self.num_heads\n",
        "        )  # size: (b c h s dk)\n",
        "\n",
        "\n",
        "        QKT = torch.einsum('bchsd,bchdt->bchst', Q, KT)\n",
        "        # size: b, c, h, seq, seq\n",
        "        # attention matrix\n",
        "        # row specifies weights for the value vectors, row add up; to one\n",
        "        A = F.softmax(QKT / np.sqrt(self.dk) + B, dim=4)  # shape: b, c, h, seq, seq\n",
        "        V = torch.einsum('bchst,bchtd->bchsd', A, V) #shape: b, c, h, seq, dk\n",
        "        V = V * Gate\n",
        "        V = einops.rearrange(V, 'b c h s d-> b c s (h d)') #shape: b, c, seq, h*dk\n",
        "        output = self.WO(V)\n",
        "        return output"
      ],
      "metadata": {
        "id": "uufSueO765iW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Column Attention"
      ],
      "metadata": {
        "id": "8xfl0vJn7UNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ColAttention(nn.Module):\n",
        "    '''Self Attention'''\n",
        "\n",
        "    def __init__(self, d, dk,num_heads):\n",
        "        '''define WQ, WK, WV projection matrices:\n",
        "        d: d_model is the original model dimension\n",
        "        dk: projection dimension for query, keys and values\n",
        "        '''\n",
        "        super(ColAttention, self).__init__()\n",
        "        \n",
        "        self.d = d  # d_model\n",
        "        self.dk = dk  # d_k: projection dimension\n",
        "        self.num_heads = num_heads  # number of attention heads\n",
        "        self.G_map = nn.Linear(256,1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.WQ = nn.Linear(self.d, self.dk * self.num_heads, bias=False)\n",
        "        self.WK = nn.Linear(self.d, self.dk * self.num_heads, bias=False)\n",
        "        self.WV = nn.Linear(self.d, self.dk * self.num_heads, bias=False)\n",
        "        self.WO = nn.Linear(self.dk * self.num_heads, self.d, bias=False)\n",
        "\n",
        "    def forward(self, msa_rep, pair_rep):\n",
        "        '''project the context onto key, query and value spaces and\n",
        "        return the final value vectors\n",
        "        '''\n",
        "        #print(msa_rep.shape) # batch, cluter, seq, msa=256 \n",
        "        #print(pair_rep.shape) # b,c, seq, z= 128\n",
        "        \n",
        "        msa_col_rep = einops.rearrange(msa_rep, 'b c s m-> b s c m')\n",
        "        # shape: b, seq, c, 256\n",
        "        Gate = self.G_map(msa_col_rep)\n",
        "        Gate = self.sigmoid(Gate).unsqueeze(2) # b,1,gate,seq\n",
        "\n",
        "        # input shape: (batch_size, block_size, d)\n",
        "        # let batch_size=b, block_size=l, num_heads=h\n",
        "        Q = self.WQ(msa_col_rep)  # shape: b, seq, c, h*dk\n",
        "        K = self.WK(msa_col_rep)  # shape: b, seq, c, h*dk\n",
        "        V = self.WV(msa_col_rep)  # shape: b, seq, c, h*dk\n",
        "\n",
        "        \n",
        "        # split Q, K, V into heads and dk, move heads up front; KT is transpose of K\n",
        "        Q = einops.rearrange(\n",
        "            Q, 'b seq c (h dk)-> b seq h c dk', h=self.num_heads\n",
        "        )  # size: (b seq h c dk)\n",
        "        KT = einops.rearrange(\n",
        "            K, 'b seq c (h dk)-> b seq h dk c', h=self.num_heads\n",
        "        )  # size: (b seq h dk c)\n",
        "        V = einops.rearrange(\n",
        "            V, 'b seq c (h dk)-> b seq h c dk', h=self.num_heads\n",
        "        )  # size: (b seq h c dk)\n",
        "\n",
        "        QKT = torch.einsum('bshcd,bshdm->bshcm', Q, KT)\n",
        "        # shape: b, seq, h, c, c\n",
        "        # attention matrix\n",
        "        # row specifies weights for the value vectors, row add up; to one\n",
        "        A = F.softmax(QKT / np.sqrt(self.dk), dim=4)  # shape: b, seq, h, c, c\n",
        "        # new value representation\n",
        "        V = torch.einsum('bshcd,bshde->bshce', A, V) #shape: b, seq, h, c, dk\n",
        "        V - V * Gate #shape: b, seq, h, c, dk \n",
        "        V = einops.rearrange(V, 'b s h c d-> b c s (h d)') #shape: b, c, seq, h*dk\n",
        "        output = self.WO(V)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "ZRyoWW5X7XA6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MSA Information"
      ],
      "metadata": {
        "id": "WEAVxVSH7jie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MSA_Information(nn.Module):\n",
        "    '''Separate Headed Self Attention: List of Attention Heads\n",
        "    This is a straightforward implementation of the multiple heads.\n",
        "    We have separate WQ, WK and WV matrices, one per head.'''\n",
        "\n",
        "    def __init__(self):\n",
        "        '''create separate heads:\n",
        "        d: d_model dimension\n",
        "        dk: projection dimension for query, keys and values\n",
        "        num_heads: number of attention heads\n",
        "        '''\n",
        "        super(MSA_Information, self).__init__()\n",
        "        self.row_attention = RowAttention(256,32,8)\n",
        "        self.col_attention = ColAttention(256,32,8)\n",
        "        #trans\n",
        "        self.project_up = nn.Linear(256,256*4, bias=False)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.project_down = nn.Linear(256*4,256, bias=False)\n",
        "        #temp_project_down\n",
        "        self.project_c = nn.Linear(256,4, bias=False) \n",
        "        self.project_z = nn.Linear(4*4,128, bias=False) # use 8 instead of 32\n",
        "        \n",
        "    def forward(self, msa_rep, pair_rep):\n",
        "        output_row = self.row_attention(msa_rep, pair_rep)\n",
        "        output = msa_rep + output_row\n",
        "        output_col = self.col_attention(output, pair_rep)\n",
        "        output = output_col + output\n",
        "        # trans\n",
        "        output_trans = self.project_up(output)\n",
        "        output_trans = self.relu(output_trans)\n",
        "        output_trans = self.project_down(output_trans)\n",
        "        output = output_trans + output\n",
        "        output = self.project_c(output)  # project c to calculate outer product\n",
        "\n",
        "        outer_product = torch.einsum('bcxm,bcyn->bcxymn', output, output) \n",
        "        #5*16*256*256*32*32\n",
        "        outer_product = torch.mean(outer_product,axis=1)\n",
        "        outer_product = einops.rearrange(outer_product, 'a b c i j-> a b c (i j)')\n",
        "        #print(outer_product.shape)\n",
        "        outer_product = self.project_z(outer_product)\n",
        "        outer_product = outer_product + pair_rep\n",
        "        return outer_product"
      ],
      "metadata": {
        "id": "XpQbA3Y27l6Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Triangular Multiplicative Update"
      ],
      "metadata": {
        "id": "opgA6R2MsBBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tri_Multi(nn.Module):\n",
        "    def __init__(self, c_z, c, mode):\n",
        "        super(Tri_Multi, self).__init__()\n",
        "\n",
        "        self.A = nn.Linear(c_z, c, bias=False)\n",
        "        self.B = nn.Linear(c_z, c, bias=False)\n",
        "        self.G_A = nn.Linear(c_z, c, bias=False)\n",
        "        self.G_B = nn.Linear(c_z, c, bias=False)\n",
        "        self.G = nn.Linear(c_z, c, bias=False)\n",
        "        # project back to original dim\n",
        "        self.pb = nn.Linear(c, c_z, bias=False)\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input dim: B x Nseq x Nseq x c_z\n",
        "        new_z = torch.clone(x)\n",
        "\n",
        "        A = self.A(x)\n",
        "        B = self.B(x)\n",
        "        if self.mode == 'in':\n",
        "            A = torch.transpose(A, 1, 2)\n",
        "            B = torch.transpose(B, 1, 2)\n",
        "\n",
        "        G_A = torch.sigmoid(self.G_A(x))\n",
        "        G_B = torch.sigmoid(self.G_B(x))\n",
        "        G = torch.sigmoid(self.G(x))\n",
        "\n",
        "        A = A * G_A\n",
        "        B = B * G_B\n",
        "\n",
        "        # compute the pair wise element wise\n",
        "        ele_mult = torch.einsum('bijk,bajk->biajk', A, B)\n",
        "        new_z = torch.sum(ele_mult, dim=3)\n",
        "\n",
        "        new_z = self.pb(new_z)\n",
        "        #print(new_z.shape)\n",
        "\n",
        "        return new_z"
      ],
      "metadata": {
        "id": "Z9WJ0BjVsIHb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Triangular Attention (Starting)"
      ],
      "metadata": {
        "id": "PXqjuXClShFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tri_Attn(nn.Module):\n",
        "    def __init__(self, c_z, c, mode):\n",
        "        super(Tri_Attn, self).__init__()\n",
        "\n",
        "        self.W_Q = nn.Linear(c_z, c, bias=False)\n",
        "        self.W_K = nn.Linear(c_z, c, bias=False)\n",
        "        self.W_V = nn.Linear(c_z, c, bias=False)\n",
        "        self.W_G = nn.Linear(c_z, c, bias=False)\n",
        "        self.W_B = nn.Linear(c_z, 1, bias=False)\n",
        "\n",
        "        self.c = c\n",
        "        self.mode = mode\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # input dim: B x Nseq x Nseq x c_z\n",
        "        \n",
        "        Q = self.W_Q(x)\n",
        "        K = self.W_K(x)\n",
        "        V = self.W_V(x)\n",
        "        G = self.W_G(x)\n",
        "        \n",
        "        N_seq = x.size(dim=1)\n",
        "        B = self.W_B(x)\n",
        "        B = B.reshape((len(x), N_seq, N_seq))\n",
        "        B = torch.transpose(B, 1, 2)\n",
        "\n",
        "        # for each batch, pick one slice at a time\n",
        "        new_z = torch.zeros(len(x), N_seq, N_seq, self.c).to(\"cuda\")\n",
        "        for i in range(N_seq):\n",
        "            A_i = torch.matmul(Q[:,i,:,:], torch.transpose(K[:,i,:,:], 1, 2)) \\\n",
        "                / torch.sqrt(torch.tensor(self.c)) + B\n",
        "            if self.mode == 'end':\n",
        "                A_i = torch.matmul(Q[:,i,:,:], K[:,i,:,:]) \\\n",
        "                / torch.sqrt(torch.tensor(self.c)) + B\n",
        "            A_I = F.softmax(A_i, dim=1)\n",
        "            O_i = G[:,i,:,:] * torch.matmul(A_i, V[:,i,:,:])\n",
        "            new_z[:,i,:,:] = O_i\n",
        "        \n",
        "        return new_z\n",
        "\n",
        "class SepHead_Tri_Attn(nn.Module):\n",
        "    def __init__(self, c_z, c, n_heads, mode):\n",
        "        super(SepHead_Tri_Attn, self).__init__()\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "        self.ta_layers = nn.ModuleList()\n",
        "        for i in range(self.n_heads):\n",
        "            self.ta_layers.append(Tri_Attn(c_z, c, mode))\n",
        "        \n",
        "        self.W_O = nn.Linear(c*n_heads, c_z, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        V = []\n",
        "        for i in range(self.n_heads):\n",
        "            V.append(self.ta_layers[i](x))\n",
        "        \n",
        "        V = torch.cat(V, dim=3)\n",
        "\n",
        "        x = self.W_O(V)\n",
        "\n",
        "        return x\n",
        "\n",
        "class MultiHead_Tri_Attn(nn.Module):\n",
        "    def __init__(self, c_z, c, n_heads, mode):\n",
        "        super(MultiHead_Tri_Attn, self).__init__()\n",
        "\n",
        "        self.W_Q = nn.Linear(c_z, c*n_heads, bias=False)\n",
        "        self.W_K = nn.Linear(c_z, c*n_heads, bias=False)\n",
        "        self.W_V = nn.Linear(c_z, c*n_heads, bias=False)\n",
        "        self.W_G = nn.Linear(c_z, c*n_heads, bias=False)\n",
        "        self.W_O = nn.Linear(c*n_heads, c_z, bias=False)\n",
        "        self.W_B = nn.Linear(c_z, 1*n_heads, bias=False)\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "        self.c = c\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input dim: B x Nseq x Nseq x c_z\n",
        "        Q = self.W_Q(x) # size: (B, Nseq, Nseq, n_heads*c)\n",
        "        K = self.W_K(x) # size: (B, Nseq, Nseq, n_heads*c)\n",
        "        V = self.W_V(x) # size: (B, Nseq, Nseq, n_heads*c)\n",
        "        G = self.W_G(x) # size: (B, Nseq, Nseq, n_heads*c)\n",
        "        B = self.W_B(x) # size: (B, Nseq, Nseq, n_heads*1)\n",
        "\n",
        "        if self.mode == 'end':\n",
        "            K = torch.transpose(K, 1, 2)\n",
        "\n",
        "        Q = einops.rearrange(\n",
        "            Q, 'b n s (h c) -> b n h s c', h = self.n_heads\n",
        "        )\n",
        "        KT = einops.rearrange(\n",
        "            K, 'b n s (h c) -> b n h c s', h = self.n_heads\n",
        "        )\n",
        "        V = einops.rearrange(\n",
        "            V, 'b n s (h c) -> b n h s c', h = self.n_heads\n",
        "        )\n",
        "        G = einops.rearrange(\n",
        "            G, 'b n s (h c) -> b n h s c', h = self.n_heads\n",
        "        )\n",
        "\n",
        "        N_seq = x.size(dim=1)\n",
        "        B = einops.rearrange(\n",
        "            B, 'b n s (h c) -> b h n s c', h = self.n_heads\n",
        "        )\n",
        "        B = torch.squeeze(B)\n",
        "        B = B.repeat(N_seq, 1, 1, 1, 1)\n",
        "        B = einops.rearrange(\n",
        "            B, 'x b h n s -> b x h n s', h = self.n_heads\n",
        "        )\n",
        "\n",
        "        QKT = torch.einsum('bnhij,bnhjk->bnhik', Q, KT)\n",
        "        A = F.softmax((QKT + B) / np.sqrt(self.c), dim=4)\n",
        "\n",
        "        V = torch.einsum('bnhij,bnhjk->bnhik', A, V)\n",
        "        V = V * G\n",
        "        V = einops.rearrange(V, 'b n h s c -> b n s (h c)')\n",
        "\n",
        "        x = self.W_O(V)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZD4l1Y-RSotL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Triangular Attention Block"
      ],
      "metadata": {
        "id": "SgGyLiI4Y6UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tri_Attn_Block(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Tri_Attn_Block, self).__init__()\n",
        "\n",
        "        self.tri_in = Tri_Multi(128, 16, 'out')\n",
        "        self.tri_out = Tri_Multi(128, 16, 'in')\n",
        "        self.tri_start = MultiHead_Tri_Attn(128, 16, 4, 'start')\n",
        "        self.tri_end = MultiHead_Tri_Attn(128, 16, 4, 'end')\n",
        "        self.trans_up = nn.Linear(128, 128*4, bias=False)\n",
        "        self.trans_down = nn.Linear(128*4, 128, bias=False)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        tri_in_out = self.tri_in(x)\n",
        "        x = x + tri_in_out\n",
        "        tri_out_out = self.tri_out(x)\n",
        "        x = x + tri_out_out\n",
        "        tri_start_out = self.tri_start(x)\n",
        "        x = x + tri_start_out\n",
        "        tri_end_out = self.tri_end(x)\n",
        "        x = x + tri_end_out\n",
        "        x = self.trans_up(x)\n",
        "        x = self.trans_down(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "5q1iWe7eY9MT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alphafold 2"
      ],
      "metadata": {
        "id": "3aaZCVb-ANBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Alphafold2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Alphafold2, self).__init__()\n",
        "\n",
        "        self.pr = PairRep()\n",
        "        self.msa = MSA(16)\n",
        "        self.msa_info = MSA_Information()\n",
        "        self.tri_attn_b = Tri_Attn_Block()\n",
        "        self.fc = nn.Linear(128, 64, bias=False)\n",
        "        self.fc_angle = nn.Linear(128,1296,bias=False)\n",
        "        self.max_pool_i = nn.MaxPool2d(kernel_size=(256,1))\n",
        "        self.max_pool_j = nn.MaxPool2d(kernel_size=(1,256))\n",
        "\n",
        "    def forward(self, seq, evo):\n",
        "        pair_rep = self.pr(seq)\n",
        "        msa_rep = self.msa(evo)\n",
        "        Z = self.msa_info(msa_rep, pair_rep)\n",
        "        Z = self.tri_attn_b(Z)\n",
        "        Angle = self.fc_angle(Z)\n",
        "        Angle = einops.rearrange(Angle, 'b s t c-> b c s t')\n",
        "        Angle_i = self.max_pool_i(Angle).squeeze(2)\n",
        "        Angle_j = self.max_pool_j(Angle).squeeze(3)\n",
        "        Angle_out = torch.cat((Angle_i, Angle_j),dim=2)\n",
        "\n",
        "        return Z, Angle_out"
      ],
      "metadata": {
        "id": "Kv2J0HrmAPK8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Bin"
      ],
      "metadata": {
        "id": "qQbHB2XvOwdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin = []\n",
        "n = 2\n",
        "gap = 20 / 64\n",
        "while n < 22:\n",
        "    bin.append(n)\n",
        "    n += gap\n",
        "\n",
        "angle_bin_w = 6.30/36\n",
        "angle_bin = torch.arange(-3.15+angle_bin_w,3.15+angle_bin_w,angle_bin_w)"
      ],
      "metadata": {
        "id": "THWJ8cqfOsnt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Dataset Class"
      ],
      "metadata": {
        "id": "vyOmxFY28pDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angle_bin(input_angles):\n",
        "  indices = torch.searchsorted(angle_bin,input_angles)\n",
        "  angles_discrete = indices[:,:,0]*36 + indices[:,:,1]\n",
        "  angles_discrete = angles_discrete\n",
        "  return angles_discrete\n",
        "\n",
        "def prepossess_data(seqs, evos, angs, masks, dmats, dmat_masks, overlap=32):\n",
        "  # zero padding the data block, distance map and mask\n",
        "  seq_len = seqs.size(dim=1)\n",
        "  m = nn.ZeroPad2d((0, 0, 128, 128))\n",
        "  seqs = m(seqs)\n",
        "  evos = m(evos)\n",
        "  angs = get_angle_bin(angs.contiguous())\n",
        "\n",
        "  angs = F.pad(angs,(128,128), \"constant\", 0)\n",
        "  masks = F.pad(masks,(128,128), \"constant\", 0)\n",
        "  m = nn.ZeroPad2d(128)\n",
        "  dmats_p = m(dmats)\n",
        "  dmat_masks_p = m(dmat_masks)\n",
        "  start_pos = torch.randint(32, (1,))\n",
        "  start_pos = int(start_pos[0])\n",
        "  pos_x = start_pos\n",
        "  if seq_len < 40:\n",
        "    pos_x = 0\n",
        "  sc_list = list()\n",
        "  ec_list = list()\n",
        "  ang_list = list()\n",
        "  mask_list = list()\n",
        "  dmat_crop_list = list()\n",
        "  d_mask_crop_list = list()\n",
        "  for i in range(pos_x, seq_len, overlap):\n",
        "    seq_crop = seqs[:,pos_x:pos_x+256,:]\n",
        "    evo_crop = evos[:,pos_x:pos_x+256,:]\n",
        "    ang_crop = angs[:,pos_x:pos_x+256]\n",
        "    mask_crop = masks[:,pos_x:pos_x+256]\n",
        "   \n",
        "    #seq_crop = PairRep(seq_crop)\n",
        "    dmat_crop = T.functional.crop(dmats_p, i, i, 256, 256)\n",
        "    dmat_crop = np.searchsorted(bin, dmat_crop)\n",
        "    dmat_crop[dmat_crop > 63] = 63\n",
        "    dmat_crop = torch.tensor(dmat_crop.tolist())\n",
        "    d_mask_crop = T.functional.crop(dmat_masks_p, i, i, 256, 256)\n",
        "    for j in range(seq_crop.shape[0]):\n",
        "      sc_list.append(seq_crop[j])\n",
        "      ec_list.append(evo_crop[j])\n",
        "      ang_list.append(ang_crop[j])\n",
        "      mask_list.append(mask_crop[j])\n",
        "      dmat_crop_list.append(dmat_crop[j])\n",
        "      d_mask_crop_list.append(d_mask_crop[j])\n",
        "  return sc_list, ec_list, ang_list, mask_list, dmat_crop_list, d_mask_crop_list\n",
        "  "
      ],
      "metadata": {
        "id": "XRhsjFUA8MfU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class AlphaFold_IterableDataset(torch.utils.data.IterableDataset):\n",
        "  def __init__(self, raw_data, num_workers,overlap=32):\n",
        "    super(AlphaFold_IterableDataset).__init__()\n",
        "    self.raw_data = raw_data \n",
        "    #how many workers\n",
        "    if num_workers <= 0:\n",
        "      self.num_workers = 1\n",
        "    else:\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "    self.raw_data_list = [[]*4 for _ in range(self.num_workers)]\n",
        "    self.overlap = overlap\n",
        " \n",
        "    for idx, raw_data_info in enumerate(self.raw_data):\n",
        "      parallel_idx = idx % self.num_workers\n",
        "      self.raw_data_list[parallel_idx].append(raw_data_info)\n",
        "  def __iter__(self):\n",
        "    worker = torch.utils.data.get_worker_info()\n",
        "    if worker is not None:\n",
        "        worker_id = worker.id\n",
        "        num_workers = worker.num_workers\n",
        "    else:\n",
        "        worker_id = 0\n",
        "        num_workers = 1\n",
        "    for m, batch in enumerate(self.raw_data_list[worker_id]):\n",
        "      seqs, evos, angs, masks, dmats, dmat_masks = get_seq_features(batch)\n",
        "      sc_list, ec_list, ang_list, mask_list, dmat_crop_list, d_mask_crop_list = prepossess_data(seqs, evos, angs, masks, dmats, dmat_masks, overlap=32)\n",
        "      for i, data_info in enumerate(zip(sc_list, ec_list, ang_list, mask_list, dmat_crop_list, d_mask_crop_list)):\n",
        "          yield data_info\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.raw_data) * 26 * int(207 / self.overlap)"
      ],
      "metadata": {
        "id": "KRH67U-t7d8j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, optimizer):\n",
        "    checkpoint = {\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()}\n",
        "    torch.save(checkpoint, 'checkpoint_2epoch.pth')"
      ],
      "metadata": {
        "id": "w8zLITW3I_HX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Alphafold2()\n",
        "model = model.to(device)\n",
        "checkpoint = torch.load('checkpoint_2epoch.pth')\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "model.train()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00008)\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "count = 0\n",
        "dataset = AlphaFold_IterableDataset(data['train'], num_workers=4)\n",
        "batch_size = 3\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size,shuffle=False, num_workers=4)\n",
        "epochs = 1\n",
        "final_loss = None\n",
        "for epoch in range(1, epochs + 1):\n",
        "  sum_loss = 0\n",
        "  for batch_idx, (seq, evo, ang,mask, dmat, dmats_mask) in enumerate(tqdm(train_loader)):\n",
        "    seq, evo, ang, mask, dmat, dmats_mask = seq.to(device), evo.to(device), \\\n",
        "    ang.to(device), mask.to(device), dmat.to(device), dmats_mask.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output_dist, output_angle = model(seq, evo)\n",
        "    \n",
        "    dmat = dmat * dmats_mask\n",
        "    ang = ang *mask\n",
        "\n",
        "    ang_label = torch.cat((ang,ang),dim=1)\n",
        "    pred = einops.rearrange(output_dist, 'b h w c -> b c h w')\n",
        "    loss_dist = F.cross_entropy(pred, dmat)\n",
        "    loss_angle = F.cross_entropy(output_angle,ang_label)\n",
        "    loss = loss_dist + loss_angle * 0.001\n",
        "    sum_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    del seq\n",
        "    del evo\n",
        "    del ang \n",
        "    del mask\n",
        "    del dmat\n",
        "    del dmats_mask\n",
        "    gc.collect()\n",
        "    #print(loss.item())\n",
        "  final_loss = sum_loss / len(train_loader)\n",
        "  print('epoch: {}, loss: {:.3f}'.format(epoch, final_loss))\n",
        "  save_model(model, optimizer)\n",
        "\n",
        "print('Final loss {:.3f}'.format(final_loss))\n",
        "print(\"Finish\")"
      ],
      "metadata": {
        "id": "WQ4wb7_t-lnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680271dc-657e-4a6c-bdcd-089e1da8ef89"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 21448/32864 [3:13:44<1:43:07,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 0.813\n",
            "Final loss 0.813\n",
            "Finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset For Testing"
      ],
      "metadata": {
        "id": "BQjNABalypiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Alphafold_Dataset_Test(IterableDataset):\n",
        "    def __init__(self, seqs, evos, overlap=32):\n",
        "        super(Alphafold_Dataset_Test).__init__()\n",
        "\n",
        "        self.seq_len = seqs.size(dim=1)\n",
        "        self.batch_size = seqs.size(dim=0)\n",
        "\n",
        "        m = nn.ZeroPad2d((0, 0, 128, 128))\n",
        "        self.seqs = m(seqs)\n",
        "        self.evos = m(evos)\n",
        "\n",
        "        self.overlap = overlap\n",
        "        \n",
        "    def __iter__(self):\n",
        "        start_pos = torch.randint(32, (1,))\n",
        "        start_pos = int(start_pos[0])\n",
        "        pos_x = start_pos\n",
        "        if self.seq_len < 36:\n",
        "            pos_x = 0\n",
        "        for i in range(pos_x, self.seq_len, self.overlap):\n",
        "            seq_crop = self.seqs[:,pos_x:pos_x+256,:]\n",
        "            evo_crop = self.evos[:,pos_x:pos_x+256,:]\n",
        "            for j in range(self.batch_size):\n",
        "                yield seq_crop[j], evo_crop[j], i, i"
      ],
      "metadata": {
        "id": "8pkxTOXXyovj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function For Validation and Testing"
      ],
      "metadata": {
        "id": "6ubH23X5x9pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "def get_recall(pred, true, seq_len):\n",
        "    pred = np.array(pred)\n",
        "    true = np.array(true)\n",
        "    num_true = np.count_nonzero(true > 0.5)\n",
        "    denom = min(num_true, seq_len)\n",
        "    short_pred_sort = np.argsort(-1*pred)\n",
        "    short_pred_top = pred[short_pred_sort][0:denom]\n",
        "    short_pred_top[short_pred_top>0.5] = 1\n",
        "    short_pred_top[short_pred_top!=1] = 0\n",
        "    short_true_top = true[short_pred_sort][0:denom]\n",
        "    \n",
        "    # print(short_true_top)\n",
        "    # print(short_pred_top)\n",
        "    recall = recall_score(short_true_top, short_pred_top, average='binary', zero_division=0)\n",
        "    \n",
        "    return recall\n",
        "    #return"
      ],
      "metadata": {
        "id": "B4GoFRCZyHb-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall_short_L = 0\n",
        "recall_short_L_2 = 0\n",
        "recall_short_L_5 = 0\n",
        "recall_medium_L = 0\n",
        "recall_medium_L_2 = 0\n",
        "recall_medium_L_5 = 0\n",
        "recall_long_L = 0\n",
        "recall_long_L_2 = 0\n",
        "recall_long_L_5 = 0\n",
        "def valid_test(seqs, evos, dmats, dmat_masks, model):\n",
        "    batch_size = 1\n",
        "    seq_len = seqs.size(dim=1)\n",
        "    #print(seq_len)\n",
        "    dataset = Alphafold_Dataset_Test(seqs, evos)\n",
        "    valid_loader = du.DataLoader(dataset=dataset, batch_size=batch_size)\n",
        "    \n",
        "    #contact_true = np.searchsorted(bin, dmats)\n",
        "    contact_true = torch.clone(dmats)\n",
        "    contact_true[contact_true <= 8.0] = 1\n",
        "    contact_true[contact_true != 1] = 0\n",
        "    contact_true = torch.tensor(contact_true.tolist()[0]).to(torch.int)\n",
        "    \n",
        "    global recall_short_L\n",
        "    global recall_short_L_2\n",
        "    global recall_short_L_5\n",
        "    global recall_medium_L\n",
        "    global recall_medium_L_2\n",
        "    global recall_medium_L_5\n",
        "    global recall_long_L\n",
        "    global recall_long_L_2\n",
        "    global recall_long_L_5\n",
        "    \n",
        "    # store the tensors for the position when overlapping\n",
        "    pos_tensor = dict()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (seq, evo, pos_i, pos_j) in enumerate(valid_loader):\n",
        "            seq, evo = seq.to(device), evo.to(device)\n",
        "            \n",
        "            output, ang_output = model(seq, evo)\n",
        "            #output = einops.rearrange(output, 'b h w c -> b c h w')\n",
        "            output = F.softmax(output, dim=3)\n",
        "            \n",
        "            pos_i, pos_j = int(pos_i[0]), int(pos_j[0])\n",
        "            \n",
        "            for idx_i, (i) in enumerate(range(pos_i, pos_i+256)):\n",
        "                for idx_j, (j) in enumerate(range(pos_j, pos_j+256)):\n",
        "                    if (i, j) not in pos_tensor:\n",
        "                        pos_tensor[(i, j)] = []\n",
        "                        pos_tensor[(i, j)].append(output[0,idx_i,idx_j,:])\n",
        "                    else:\n",
        "                        pos_tensor[(i, j)].append(output[0,idx_i,idx_j,:])\n",
        "    \n",
        "    # compute the mean probability\n",
        "    pred = []\n",
        "    for i in range(128, 128+seq_len):\n",
        "        row = []\n",
        "        for j in range(128, 128+seq_len):\n",
        "            if (i, j) not in pos_tensor:\n",
        "                row.append(0)\n",
        "            else:\n",
        "                pos_tensor[(i, j)] = sum(pos_tensor[(i, j)]) / \\\n",
        "                                    len(pos_tensor[(i, j)])\n",
        "                row.append(torch.sum(pos_tensor[(i, j)][0:20]))\n",
        "        pred.append(row)\n",
        "    \n",
        "    pred = torch.tensor(pred)\n",
        "    pred = pred * dmat_masks[0]\n",
        "    \n",
        "    #print(pred)\n",
        "    short_pred = []\n",
        "    short_true = []\n",
        "    # short contact\n",
        "    for i in range(6, 12):\n",
        "        diag = torch.diagonal(pred, i, dim1=0, dim2=1)\n",
        "        short_pred.extend(diag.tolist())\n",
        "        diag = torch.diagonal(contact_true, i, dim1=0, dim2=1)\n",
        "        short_true.extend(diag.tolist())\n",
        "    \n",
        "    # compute L size\n",
        "    get_recall(short_pred, short_true, seq_len)\n",
        "    res = get_recall(short_pred, short_true, seq_len)\n",
        "    recall_short_L += res\n",
        "    \n",
        "    # L / 2\n",
        "    res = get_recall(short_pred, short_true, int(seq_len/2))\n",
        "    recall_short_L_2 += res\n",
        "    \n",
        "    # L / 5\n",
        "    res = get_recall(short_pred, short_true, int(seq_len/5))\n",
        "    recall_short_L_5 += res\n",
        "    \n",
        "    medium_pred = []\n",
        "    medium_true = []\n",
        "    # medium contact\n",
        "    for i in range(12, 24):\n",
        "        diag = torch.diagonal(pred, i, dim1=0, dim2=1)\n",
        "        medium_pred.extend(diag.tolist())\n",
        "        diag = torch.diagonal(contact_true, i, dim1=0, dim2=1)\n",
        "        medium_true.extend(diag.tolist())\n",
        "    \n",
        "    # compute L size\n",
        "    res = get_recall(medium_pred, medium_true, seq_len)\n",
        "    recall_medium_L += res\n",
        "    \n",
        "    # L / 2\n",
        "    res = get_recall(medium_pred, medium_true, int(seq_len/2))\n",
        "    recall_medium_L_2 += res\n",
        "    \n",
        "    # L / 5\n",
        "    res = get_recall(medium_pred, medium_true, int(seq_len/5))\n",
        "    recall_medium_L_5 += res\n",
        "    \n",
        "    long_pred = []\n",
        "    long_true = []\n",
        "    # long contact\n",
        "    for i in range(24, seq_len):\n",
        "        diag = torch.diagonal(pred, i, dim1=0, dim2=1)\n",
        "        long_pred.extend(diag.tolist())\n",
        "        diag = torch.diagonal(contact_true, i, dim1=0, dim2=1)\n",
        "        long_true.extend(diag.tolist())\n",
        "    \n",
        "    # compute L size\n",
        "    res = get_recall(long_pred, long_true, seq_len)\n",
        "    recall_long_L += res\n",
        "    \n",
        "    # L / 2\n",
        "    res = get_recall(long_pred, long_true, int(seq_len/2))\n",
        "    recall_long_L_2 += res\n",
        "    \n",
        "    # L / 5\n",
        "    res = get_recall(long_pred, long_true, int(seq_len/5))\n",
        "    recall_long_L_5 += res\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "NWZGqQZCyd8n"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "SzJK00Aa7Vbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = scn.load(casp_version=7, with_pytorch=\"dataloaders\", \n",
        "                seq_as_onehot=True, aggregate_model_input=False,\n",
        "               batch_size=1)\n",
        "checkpoint = torch.load('checkpoint_2epoch.pth')\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "model.eval()\n",
        "count = 0\n",
        "for batch in tqdm(data['valid-10']):\n",
        "    seqs, evos, angs, masks, dmats, dmat_masks = get_seq_features(batch)\n",
        "    valid_test(seqs, evos, dmats, dmat_masks, model)\n",
        "\n",
        "    gc.collect()\n",
        "    \n",
        "    count += 1\n",
        "    # if count == 1:\n",
        "    #     break\n",
        "print('Validation short accuracy L: {:.3f}'.format(recall_short_L/count))\n",
        "print('Validation short accuracy L/2: {:.3f}'.format(recall_short_L_2/count))\n",
        "print('Validation short accuracy L/5: {:.3f}'.format(recall_short_L_5/count))\n",
        "print('Validation medium accuracy L: {:.3f}'.format(recall_medium_L/count))\n",
        "print('Validation medium accuracy L/2: {:.3f}'.format(recall_medium_L_2/count))\n",
        "print('Validation medium accuracy L/5: {:.3f}'.format(recall_medium_L_5/count))\n",
        "print('Validation long accuracy L: {:.3f}'.format(recall_long_L/count))\n",
        "print('Validation long accuracy L/2: {:.3f}'.format(recall_long_L_2/count))\n",
        "print('Validation long accuracy L/5: {:.3f}'.format(recall_long_L_5/count))"
      ],
      "metadata": {
        "id": "5FleF8NI7Ykm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7da5b5e-6183-4e94-e60d-27c3ee8974b1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SidechainNet was loaded from ./sidechainnet_data/sidechainnet_casp7_30.pkl.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [03:28<00:00,  6.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation short accuracy L: 0.594\n",
            "Validation short accuracy L/2: 0.594\n",
            "Validation short accuracy L/5: 0.500\n",
            "Validation medium accuracy L: 0.531\n",
            "Validation medium accuracy L/2: 0.500\n",
            "Validation medium accuracy L/5: 0.375\n",
            "Validation long accuracy L: 0.469\n",
            "Validation long accuracy L/2: 0.438\n",
            "Validation long accuracy L/5: 0.281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "kLs-B1ek-CPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "recall_short_L = 0\n",
        "recall_short_L_2 = 0\n",
        "recall_short_L_5 = 0\n",
        "recall_medium_L = 0\n",
        "recall_medium_L_2 = 0\n",
        "recall_medium_L_5 = 0\n",
        "recall_long_L = 0\n",
        "recall_long_L_2 = 0\n",
        "recall_long_L_5 = 0\n",
        "for batch in tqdm(data['test']):\n",
        "    seqs, evos, angs, masks, dmats, dmat_masks = get_seq_features(batch)\n",
        "    valid_test(seqs, evos, dmats, dmat_masks, model)\n",
        "\n",
        "    gc.collect()\n",
        "    \n",
        "    count += 1\n",
        "\n",
        "print('Test short accuracy L: {:.3f}'.format(recall_short_L/count))\n",
        "print('Test short accuracy L/2: {:.3f}'.format(recall_short_L_2/count))\n",
        "print('Test short accuracy L/5: {:.3f}'.format(recall_short_L_5/count))\n",
        "print('Test medium accuracy L: {:.3f}'.format(recall_medium_L/count))\n",
        "print('Test medium accuracy L/2: {:.3f}'.format(recall_medium_L_2/count))\n",
        "print('Test medium accuracy L/5: {:.3f}'.format(recall_medium_L_5/count))\n",
        "print('Test long accuracy L: {:.3f}'.format(recall_long_L/count))\n",
        "print('Test long accuracy L/2: {:.3f}'.format(recall_long_L_2/count))\n",
        "print('Test long accuracy L/5: {:.3f}'.format(recall_long_L_5/count))"
      ],
      "metadata": {
        "id": "Ni81pyED-DWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29445622-afee-4e34-cad9-4a9574a1bea3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [09:58<00:00,  6.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test short accuracy L: 0.792\n",
            "Test short accuracy L/2: 0.781\n",
            "Test short accuracy L/5: 0.656\n",
            "Test medium accuracy L: 0.710\n",
            "Test medium accuracy L/2: 0.688\n",
            "Test medium accuracy L/5: 0.548\n",
            "Test long accuracy L: 0.774\n",
            "Test long accuracy L/2: 0.581\n",
            "Test long accuracy L/5: 0.376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}