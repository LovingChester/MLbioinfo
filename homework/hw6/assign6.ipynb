{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65781517-0082-477f-a139-b4314cea64c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sidechainnet as scn\n",
    "import einops as ein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901e6cf-9d13-436a-9932-9e2e9ee07db5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creates features for a batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b02a3-3d4b-4d7c-a892-514f4c6347ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_features(batch):\n",
    "    '''\n",
    "    Take a batch of sequence info and return the sequence (one-hot),\n",
    "    evolutionary info and (phi, psi, omega) angles per position, \n",
    "    as well as position mask.\n",
    "    Also return the distance matrix, distance mask, pids and lengths\n",
    "    '''\n",
    "    pids = batch.pids # protein ids\n",
    "    str_seqs = batch.str_seqs # seq in str format\n",
    "    seqs = batch.seqs # seq in one-hot format\n",
    "    int_seqs = batch.int_seqs # seq in int format\n",
    "    masks = batch.msks # which positions are valid\n",
    "    lengths = batch.lengths # seq length\n",
    "    evos = batch.evos # PSSM / evolutionary info\n",
    "    angs = batch.angs[:,:,0:2] # torsion angles: phi, psi\n",
    "    \n",
    "    # use coords to create distance matrix from c-beta\n",
    "    # except use c-alpha for G\n",
    "    # coords[:, 4, :] is c-beta, and coords[:, 1, :] is c-alpha\n",
    "    coords = batch.crds # seq coord info (all-atom)\n",
    "    batch_xyz = []\n",
    "    for i in range(coords.shape[0]):\n",
    "        xyz = [coords[i][cpos+4,:] \n",
    "                if masks[i][cpos//14] and str_seqs[i][cpos//14] != 'G'\n",
    "                else coords[i][cpos+1,:]\n",
    "                for cpos in range(0, coords[i].shape[0]-1, 14)]\n",
    "        batch_xyz.append(torch.stack(xyz))\n",
    "    batch_xyz = torch.stack(batch_xyz)\n",
    "    # now create pairwise distance matrix\n",
    "    dmats = torch.cdist(batch_xyz, batch_xyz)\n",
    "    # create matrix mask (0 means i,j invalid)\n",
    "    dmat_masks = torch.einsum('bi,bj->bij', masks, masks)\n",
    "    \n",
    "    return seqs, evos, angs, masks, dmats, dmat_masks, pids, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275e2b1-c761-4c9a-8258-a10323d493a3",
   "metadata": {},
   "source": [
    "## Alphafold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65e72d-8094-4b80-85dc-ebfd84e4cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class residual_block(nn.Module):\n",
    "    def __init__(self, dilation, dmodel, dproj, drop_prob):\n",
    "        super(residual_block, self).__init__()\n",
    "        self.dilation = dilation\n",
    "        self.dmodel = dmodel\n",
    "        self.dproj = dproj\n",
    "        self.drop_prob = drop_prob\n",
    "        self.dilation_kernel_size = 3\n",
    "\n",
    "        # from dmodel project down to dproj, then do dilated conv,\n",
    "        # followed by project up to dmodel\n",
    "        self.res_block = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.dmodel),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(self.dmodel, self.dproj, kernel_size=1), #proj down\n",
    "            nn.BatchNorm2d(self.dproj),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout2d(p=self.drop_prob),\n",
    "            nn.Conv2d(self.dproj, self.dproj,\n",
    "                      kernel_size=self.dilation_kernel_size, \n",
    "                      padding='same', dilation=self.dilation), #dilated Conv\n",
    "            nn.BatchNorm2d(self.dproj),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(self.dproj, self.dmodel, kernel_size=1) # proj up\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape: b, f, n, n\n",
    "        x = x + self.res_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AlphaFold(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dmodel, dproj, \n",
    "                 num_dilations, num_blocks, drop_prob):\n",
    "        super(AlphaFold, self).__init__()\n",
    "        self.dmodel = dmodel\n",
    "        self.dproj = dproj\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_dilations = num_dilations\n",
    "        self.num_blocks = num_blocks\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        # project to dmodel\n",
    "        self.proj_in = nn.Conv2d(self.in_channels, self.dmodel, kernel_size=1)\n",
    "        \n",
    "        # add num_groups of residual dilation blocks\n",
    "        # each block has dilations of 1, 2, 4, 8, i.e. 2^0, 2^1, 2^2, 2^3\n",
    "        res_layers = []            \n",
    "        for _ in range(self.num_blocks):\n",
    "            res_layers.extend([\n",
    "            residual_block(2**di, self.dmodel, self.dproj, self.drop_prob)\n",
    "            for di in range(self.num_dilations)])\n",
    "        self.res_blocks = nn.ModuleList(res_layers)\n",
    "\n",
    "        # compute logits for distance bins\n",
    "        self.dist_out = nn.Conv2d(self.dmodel, self.out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape: b, f, n, n\n",
    "        x = self.proj_in(x)\n",
    "        for (dil, res_block) in enumerate(self.res_blocks):\n",
    "            x = res_block(x)\n",
    "        x = self.dist_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9301ec0-776d-4b40-88ba-b565b6ad306b",
   "metadata": {},
   "source": [
    "## Dataset of Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a748e4-bb0e-4a0e-9448-cedd87b147f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crops_Dataset(torch.utils.data.IterableDataset):\n",
    "    '''Assumes that the batch from sidechainnet is already on the GPU\n",
    "       Creates a batch of crops across the entire batch of sequences \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, seqs, evos, angs, masks, dmats, dmat_masks,\n",
    "                 crop_sz, stride_sz, pad_sz, num_dist_bins, device, test=False):\n",
    "        self.seqs = seqs\n",
    "        self.evos = evos\n",
    "        self.angs = angs\n",
    "        self.masks = masks\n",
    "        self.dmats = dmats\n",
    "        self.dmat_masks = dmat_masks\n",
    "        self.crop_sz = crop_sz\n",
    "        self.stride_sz = stride_sz\n",
    "        self.pad_sz = pad_sz\n",
    "        self.num_dist_bins = num_dist_bins\n",
    "        self.device = device\n",
    "        self.test = test\n",
    "        \n",
    "        # create distance bins\n",
    "        bin_w = (22-2)/self.num_dist_bins\n",
    "        self.dist_bins = torch.arange(2+bin_w,22,bin_w).to(self.device)\n",
    "        \n",
    "        # if test set, then create place holders for the entire NxN contact map\n",
    "        if self.test:\n",
    "            B, N, _ = self.seqs.shape\n",
    "            self.cmaps = torch.zeros((B, num_dist_bins, N, N)).to(self.device)\n",
    "            self.cnts = torch.zeros((B, N, N)).to(self.device)\n",
    "\n",
    "        # pad all tensors by pad_size\n",
    "        self.pad_tensors()\n",
    "        \n",
    "        # create the list of crop start positions (si, sj)\n",
    "        self.get_start_positions()\n",
    "    \n",
    "    def pad_tensors(self):\n",
    "        '''pad all tensors by pad_sz in each relevant dim'''\n",
    "        pad_sea = (0, 0, self.pad_sz, self.pad_sz) # don't pad dim 2, pad dim 1\n",
    "        self.seqs = F.pad(self.seqs,  pad_sea)\n",
    "        self.evos = F.pad(self.evos,  pad_sea)\n",
    "        self.angs = F.pad(self.angs,  pad_sea)\n",
    "        \n",
    "        pad_masks = (self.pad_sz, self.pad_sz) # pad dim 1\n",
    "        self.masks = F.pad(self.masks,  pad_masks)\n",
    "        \n",
    "        pad_dmat = (self.pad_sz, self.pad_sz, \n",
    "                    self.pad_sz, self.pad_sz) # pad both dim 2 and 1\n",
    "        self.dmats = F.pad(self.dmats, pad_dmat)\n",
    "        self.dmat_masks = F.pad(self.dmat_masks, pad_dmat)\n",
    "\n",
    "        # also pad the contact/dist maps for test batch\n",
    "        if self.test:\n",
    "            self.cmaps = F.pad(self.cmaps, pad_dmat)\n",
    "            self.cnts = F.pad(self.cnts, pad_dmat)\n",
    "    \n",
    "    def get_start_positions(self):\n",
    "        '''Create a set of start positions si, sj for the batch\n",
    "           During training, si is chosen in (0, pad_sz) with sj > si,\n",
    "              followed by strides in both si and sj directions\n",
    "           During testing, si, sj = 0, 1\n",
    "        '''\n",
    "        N = self.seqs.shape[1]\n",
    "        self.start_pos = []\n",
    "        \n",
    "        # cover the test proteins from the start (this includes padding)\n",
    "        if self.test:\n",
    "            si, sj = 0, 1\n",
    "        else:\n",
    "            # chose si, sj in the pad_sz x pad_sz top left corner\n",
    "            si = np.random.randint(0, self.pad_sz)\n",
    "            sj = np.random.randint(si+1, self.pad_sz+1)\n",
    "        \n",
    "        # now generate other start pos si, and sj using strides \n",
    "        PI = np.arange(si, N-self.crop_sz+1, self.stride_sz)\n",
    "        PJ = np.arange(sj, N-self.crop_sz+1, self.stride_sz)\n",
    "\n",
    "        # list of all si, sj pairs\n",
    "        self.start_pos = [(i,j) for i in PI for j in PJ if i<j]\n",
    "            \n",
    "        \n",
    "    def add_pred_crop(self, crop_preds, ij_pos):\n",
    "        '''Used during testing to convert the predicted output from \n",
    "        each crop into probabilties for the 64 distance bins, and\n",
    "        adding this to the appropriate \"tile\" in the predicted cmap\n",
    "        '''\n",
    "        si, sj = ij_pos\n",
    "        B, nbins, n, n = crop_preds.shape\n",
    "        # compute softmax along the distance bins axis: dim 1\n",
    "        predicted_probs = F.softmax(crop_preds, dim=1)\n",
    "        \n",
    "        # update the cmaps info and counts\n",
    "        self.cmaps[:, :, si:si+n, sj:sj+n] += predicted_probs.detach()\n",
    "        self.cnts[:, si:si+n, sj:sj+n] += torch.ones(B, n, n).to(self.device)        \n",
    "        \n",
    "    \n",
    "    def get_cmap_data(self):\n",
    "        '''return cmap/cnt info during testing'''\n",
    "        return self.cmaps, self.cnts\n",
    "    \n",
    "    def get_dmat_data(self):\n",
    "        '''convert the true distance map into categorical bins'''\n",
    "        dmats_discrete = torch.searchsorted(self.dist_bins, \n",
    "                        self.dmats)\n",
    "        return dmats_discrete, self.dmat_masks\n",
    "    \n",
    "    def get_dist_bins(self):\n",
    "        '''return the distance bins'''\n",
    "        return self.dist_bins\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''how many si, sj pairs are there?'''\n",
    "        return len(self.start_pos)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        '''return one crop starting at si, sj *for all* sequences in a batch\n",
    "           so the crop will the B x f x 64 x 64, with features in the 2nd dim\n",
    "        '''\n",
    "        for si, sj in self.start_pos:\n",
    "            si_crop = self.seqs[:, si:si+self.crop_sz]\n",
    "            sj_crop = self.seqs[:, sj:sj+self.crop_sz]\n",
    "            ei_crop = self.evos[:, si:si+self.crop_sz]\n",
    "            ej_crop = self.evos[:, sj:sj+self.crop_sz]\n",
    "\n",
    "            # tile si_crop\n",
    "            si_ary = ein.repeat(si_crop, 'b n f -> b (n repeat) f', repeat=self.crop_sz)\n",
    "            ei_ary = ein.repeat(ei_crop, 'b n f -> b (n repeat) f', repeat=self.crop_sz)\n",
    "            # repeat sj_crop\n",
    "            sj_ary = ein.repeat(sj_crop, 'b n f -> b (repeat n) f', repeat=self.crop_sz) \n",
    "            ej_ary = ein.repeat(ej_crop, 'b n f -> b (repeat n) f', repeat=self.crop_sz)\n",
    "\n",
    "            # cat along last dim\n",
    "            seqs_crop = ein.rearrange([si_ary, sj_ary], 'a b n f -> b n (a f)')\n",
    "            evos_crop = ein.rearrange([ei_ary, ej_ary], 'a b n f -> b n (a f)')\n",
    "            evos_diff = ei_ary - ej_ary # diff\n",
    "            evos_mul = ei_ary * ej_ary # elementwise\n",
    "            \n",
    "            # make it b, crop_sz x crop_sz, f\n",
    "            seqs_crop = ein.rearrange(seqs_crop, 'a (n c) f -> a n c f', c=self.crop_sz)\n",
    "            evos_crop = ein.rearrange(evos_crop, 'a (n c) f -> a n c f', c=self.crop_sz)\n",
    "            evos_diff = ein.rearrange(evos_diff, 'a (n c) f -> a n c f', c=self.crop_sz)\n",
    "            evos_mul = ein.rearrange(evos_mul, 'a (n c) f -> a n c f', c=self.crop_sz)\n",
    "\n",
    "            # cat all together along feature dim (last)\n",
    "            crop = torch.cat([seqs_crop, evos_crop, evos_diff, evos_mul], dim=3)\n",
    "            # move features front\n",
    "            crop = ein.rearrange(crop, 'b i j f -> b f i j') \n",
    "\n",
    "            # create discretized dmat\n",
    "            crop_dmat = torch.searchsorted(self.dist_bins, \n",
    "                            self.dmats[:, si:si+self.crop_sz, sj:sj+self.crop_sz])\n",
    "            # extract the crop mask (for valid pairs)\n",
    "            crop_mask = self.dmat_masks[:, si:si+self.crop_sz, sj:sj+self.crop_sz]\n",
    "\n",
    "            # return the crop, crop dist map, crop mask, and si, sj start pos\n",
    "            yield (crop, crop_dmat, crop_mask, (si, sj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa9900-c2fb-4d97-be02-c6584a40f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(args, bidx, e, running_loss, model, optimizer):\n",
    "    ckpt_fname = f'ckpt_J{args.jobid}_e{e}.pth'\n",
    "    checkpoint = {\n",
    "        'batch': bidx,\n",
    "        'epoch': e,\n",
    "        'loss': running_loss,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, ckpt_fname)\n",
    "\n",
    "\n",
    "def load_checkpoint(args, model, optimizer, device):\n",
    "    checkpoint = torch.load(args.ckpt_fname)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    running_loss = checkpoint['loss']\n",
    "    bidx = checkpoint['batch']\n",
    "    e = checkpoint['epoch']\n",
    "    return e, bidx, running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce58ed2-7295-41b9-8b18-a56dd5209568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='alphafold.py')\n",
    "    # checkpoint file\n",
    "    parser.add_argument('-cf', dest='ckpt_fname', default=None)\n",
    "\n",
    "    parser.add_argument('-e', dest='epochs', default=10, type=int)\n",
    "    parser.add_argument('-b', dest='batch_size',\n",
    "                        default=32, type=int)\n",
    "    parser.add_argument('-lr', dest='learning_rate',\n",
    "                        default=1e-5, type=float)\n",
    "\n",
    "    # model hyperparams\n",
    "    parser.add_argument('-nb', dest='num_blocks', default=1, type=int)\n",
    "    parser.add_argument('-dmodel', dest='dmodel', default=128, type=int)\n",
    "    parser.add_argument('-dproj', dest='dproj', default=64, type=int)\n",
    "    parser.add_argument('-dilations', dest='num_dilations', default=4, type=int)\n",
    "    parser.add_argument('-dbins', dest='num_dist_bins', default=64, type=int)\n",
    "    parser.add_argument('-c', dest='crop_sz', default=64, type=int)\n",
    "    parser.add_argument('-s', dest='stride_sz', default=16, type=int)\n",
    "    parser.add_argument('-p', dest='pad_sz', default=32, type=int)\n",
    "    parser.add_argument('-dropout', dest='dropout',\n",
    "                        default=0.15, type=float)\n",
    "    parser.add_argument('-num_workers', dest='num_workers',\n",
    "                        default=1, type=int)\n",
    "    parser.add_argument('-j', dest='jobid', default='1')\n",
    "\n",
    "    cmd = '-e 2 -b 16'\n",
    "    args = parser.parse_args(cmd.split())\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d947c43-babd-44ae-a26f-22e0c065d871",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffa3e2-6d84-47b9-9249-70b8748ce44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "args = parse_args()\n",
    "print(\"ARGS\", args)\n",
    "in_channels = 124\n",
    "out_channels = args.num_dist_bins\n",
    "\n",
    "# Load CASP7 data as pytorch tensors\n",
    "data = scn.load(casp_version=7, with_pytorch=\"dataloaders\", \n",
    "                seq_as_onehot=True, aggregate_model_input=False,\n",
    "                batch_size=args.batch_size, dynamic_batching=True)\n",
    "\n",
    "model = AlphaFold(in_channels, out_channels, args.dmodel, args.dproj, \n",
    "             args.num_dilations, args.num_blocks, args.dropout)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "start_epoch = 0 # epoch number\n",
    "if args.ckpt_fname is not None:\n",
    "    saveinfo = torch.load(args.ckpt_fname)\n",
    "    start_epoch = saveinfo['epoch']+1\n",
    "    model.load_state_dict(saveinfo['state_dict'])\n",
    "    optimizer.load_state_dict(saveinfo['optimizer'])\n",
    "    print(\"resume from epoch:\", start_epoch) # resume from epoch\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "st = time.time()\n",
    "train = 'train'\n",
    "for e in range(start_epoch, args.epochs):\n",
    "    running_loss = 0\n",
    "    running_len = 0\n",
    "    for bidx, batch in tqdm(enumerate(data[train]), total=len(data[train])):\n",
    "        # get the batch info and send to GPU\n",
    "        seqs, evos, angs, masks, dmats, dmat_masks, pids, lengths = get_seq_features(batch)\n",
    "        seqs, evos, masks, dmats, dmat_masks =\\\n",
    "            seqs.to(device), evos.to(device), masks.to(device),\\\n",
    "            dmats.to(device), dmat_masks.to(device)\n",
    "\n",
    "        # dataset of crops for this batch\n",
    "        train_data = Crops_Dataset(seqs, evos, angs, masks, dmats, dmat_masks,\n",
    "            args.crop_sz, args.stride_sz, args.pad_sz, args.num_dist_bins, device)\n",
    "\n",
    "        # now iterate over the crops, which are already on GPU\n",
    "        for cidx, (crop, crop_dmat, crop_mask, ij_pos) in enumerate(train_data):\n",
    "            output = model(crop)\n",
    "            # compute entropy loss per crop element\n",
    "            loss = F.cross_entropy(output, crop_dmat, reduction='none')\n",
    "            # consider only valid positions based on crop_mask\n",
    "            loss = torch.sum(loss * crop_mask)\n",
    "\n",
    "            running_loss += loss.item() # total loss\n",
    "            running_len += torch.sum(crop_mask).item() # how many valid pos\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # save after each batch\n",
    "        save_checkpoint(args, bidx, e, running_loss, model, optimizer)\n",
    "\n",
    "    print(\"epoch\", e, running_loss, running_len, running_loss/running_len)\n",
    "\n",
    "en = time.time()\n",
    "print(\"tot time\", en-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb3b34-f5d4-46da-807f-ae71676a8ec2",
   "metadata": {},
   "source": [
    "## Class to compute prediction statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23612725-4080-40ac-90be-83ac3477fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testStats:\n",
    "    '''Aggregate the statistics for all the test proteins\n",
    "       Print out overall stats for top L, L/2, L/5 predictions,\n",
    "       which are denoted as k=1, k=2, k=5.\n",
    "       Also print prec/recall for all predictions (above dist 1), dentoed k=0\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''precision by pid, length, Lk'''\n",
    "        self.prec = defaultdict(lambda: defaultdict(dict)) #nested dict\n",
    "        \n",
    "    def print_stats(self):\n",
    "        '''print per protein precision, and compute stats over all pids'''\n",
    "        prec_Lk = defaultdict(lambda: defaultdict(list))\n",
    "        for pid in self.prec.keys():\n",
    "            for len_lbl in self.prec[pid].keys():\n",
    "                for k in self.prec[pid][len_lbl].keys():\n",
    "                    prec_Lk[len_lbl][k].append(self.prec[pid][len_lbl][k])\n",
    "                    print(\"Protein:\", pid, len_lbl, k, self.prec[pid][len_lbl][k])\n",
    "                    \n",
    "        print(\"\\nOverall Stats:\")\n",
    "        for len_lbl in prec_Lk:\n",
    "            for k in prec_Lk[len_lbl]:\n",
    "                if k >= 1:\n",
    "                    precs = [p for (p, n, l) in prec_Lk[len_lbl][k]]\n",
    "                    print(len_lbl, k, np.array(precs).mean())\n",
    "                else:\n",
    "                    precs = [p for (p, r, nc, np, nt) in prec_Lk[len_lbl][k]]\n",
    "                    recs = [r for (p, r, nc, np, nt) in prec_Lk[len_lbl][k]]\n",
    "                    print(len_lbl, k, np.array(precs).mean(), np.array(recs).mean())\n",
    "                \n",
    "   \n",
    "    def compute_lk(self, len_lbl, cmaps_pred, cmaps_true, lb, ub, pids, lengths):\n",
    "        '''Compute the precision (and recall) for given length range between\n",
    "        [lb, ub], for the top L/k predictions.\n",
    "        '''\n",
    "        \n",
    "        # create a mask for only those i,j pairs that are within [lb, ub] band\n",
    "        N = cmaps_pred.shape[1]\n",
    "        ones = torch.ones((N, N))\n",
    "        sep_mask = torch.triu(ones, diagonal=lb) * torch.tril(ones, diagonal=ub)\n",
    "        sep_mask = sep_mask.to(device)\n",
    "        \n",
    "        # filter out elements not in the lb, ub diagional band\n",
    "        cmaps_pred = cmaps_pred * sep_mask\n",
    "        cmaps_true = cmaps_true * sep_mask\n",
    "        \n",
    "        # compute stats for each protein in the batch\n",
    "        for pi in range(len(pids)):\n",
    "            pid = pids[pi]\n",
    "            L = lengths[pi]\n",
    "            cmap_p = cmaps_pred[pi] # predicted probabilities\n",
    "            cmap_t = cmaps_true[pi] # true binary cmap\n",
    "            cmap_b = torch.where(cmap_p >= 0.5, 1, 0) # predicted binary cmap\n",
    "            \n",
    "            for k in [1, 2, 5]:\n",
    "                # choose smaller of L/k or # true contacts\n",
    "                Lk = min(L//k, int(cmap_t.sum()))\n",
    "                \n",
    "                # next, find the probabilities over 0.5, extract topk of those\n",
    "                # and return a tuple that contains the positions of the topk vals\n",
    "                idxs = torch.where(cmap_p >= 0.5)\n",
    "                probs = cmap_p[idxs]\n",
    "                topk_probs = torch.topk(probs, min(Lk, len(probs)))\n",
    "                top_Lk = topk_probs.indices\n",
    "                top_tup = (idxs[0][top_Lk], idxs[1][top_Lk])\n",
    "\n",
    "                # the number of contacts common to both pred and true\n",
    "                num_correct = torch.sum(cmap_b[top_tup] * cmap_t[top_tup])\n",
    "                \n",
    "                # compute precision @ L/k\n",
    "                prec_Lk = num_correct/Lk\n",
    "                self.prec[pid][len_lbl][k] = (float(prec_Lk.cpu()), \n",
    "                                              int(num_correct.cpu()), Lk)\n",
    "            \n",
    "            # for the full protein, compute precision and recall\n",
    "            if len_lbl == 'all':\n",
    "                k = 0 # let k =0 mean no topk restriction\n",
    "                num_correct = torch.sum(cmap_b * cmap_t)\n",
    "                num_true = torch.sum(cmap_t)\n",
    "                num_preds = torch.sum(cmap_b)\n",
    "                self.prec[pid][len_lbl][k] = (float(num_correct/num_preds), \n",
    "                                              float(num_correct/num_true), \n",
    "                                              int(num_correct), int(num_preds), \n",
    "                                              int(num_true))\n",
    "            \n",
    "                \n",
    "    def update(self, cmaps, cnts, dmaps, dmap_masks, pids, lengths, dist_bins):\n",
    "        '''Take the predicted contact map probabilities for all pids in a \n",
    "        batch, and compute the precision (and recall) for various length\n",
    "        thresholds -- short, medium, long -- and overall\n",
    "        '''\n",
    "        # move dist bins (f) last\n",
    "        cmaps = ein.rearrange(cmaps, 'b f i j -> b i j f')\n",
    "        \n",
    "        cnts = cnts * dmap_masks # ignore any invalid ij pair\n",
    "        cmaps = cmaps * dmap_masks.unsqueeze(dim=3) # ignore the preds at invalid pos\n",
    "        \n",
    "        # divide cmaps by cnts, but make sure to not divide by 0\n",
    "        cnts_mask = torch.where(cnts > 0)\n",
    "        cmaps[cnts_mask] = cmaps[cnts_mask] / cnts[cnts_mask].unsqueeze(dim=1)\n",
    "        \n",
    "        # now make dist bins sum up to one (prob vector) by dividing the \n",
    "        # bins with the sum of all bins\n",
    "        cmaps_sum = cmaps.sum(dim=3, keepdim=True)\n",
    "        cmaps[cnts_mask] = cmaps[cnts_mask]/cmaps_sum[cnts_mask]\n",
    "\n",
    "        #now create cmap prob for all dists under 8A\n",
    "        bin8 = torch.searchsorted(dist_bins, 8).item()  # which bin for 8A\n",
    "        cmaps_pred = cmaps[:, :, :, 0:bin8].sum(dim=3)\n",
    "        \n",
    "        #create true cmap, and retain only valid pos\n",
    "        cmaps_true = torch.where(dmaps <= bin8, 1, 0) * dmap_masks\n",
    "    \n",
    "        # short, medium, long range contacts\n",
    "        N = cmaps_true.shape[1]\n",
    "        ranges = {'short':(6,11), 'medium':(12,23), 'long':(24, N), 'all':(2,N)}\n",
    "        for len_lbl in ['short', 'medium', 'long', 'all']:\n",
    "            lb, ub = ranges[len_lbl]\n",
    "            self.compute_lk(len_lbl, cmaps_pred, cmaps_true, lb, ub, pids, lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e8db04-5ae0-4ae9-b4d8-0b7ae7676f66",
   "metadata": {},
   "source": [
    "## Load model from checkpoint (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f26c6-2aa2-43e6-a022-02010680c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "args = parse_args()\n",
    "print(\"ARGS\", args)\n",
    "in_channels = 124\n",
    "out_channels = args.num_dist_bins\n",
    "\n",
    "# Load CASP7 data as pytorch tensors\n",
    "data = scn.load(casp_version=7, with_pytorch=\"dataloaders\", \n",
    "                seq_as_onehot=True, aggregate_model_input=False,\n",
    "                batch_size=args.batch_size, dynamic_batching=True)\n",
    "\n",
    "model = AlphaFold(in_channels, out_channels, args.dmodel, args.dproj, \n",
    "             args.num_dilations, args.num_blocks, args.dropout)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "saveinfo = torch.load(\"ckpt_aws_e2.pth\")\n",
    "model.load_state_dict(saveinfo['state_dict'])\n",
    "optimizer.load_state_dict(saveinfo['optimizer'])\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f216f1-d858-485f-af54-00d0f58d1538",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e35f5eb-b5ef-4b4e-a4d0-df821b13b335",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stride = 16\n",
    "\n",
    "model.eval()\n",
    "st = time.time()\n",
    "test_stats = testStats()\n",
    "with torch.no_grad():\n",
    "    for bidx, batch in tqdm(enumerate(data['test']), total=len(data['test'])):\n",
    "        running_loss = 0\n",
    "        running_len = 0\n",
    "        seqs, evos, angs, masks, dmats, dmat_masks, pids, lengths = get_seq_features(batch)\n",
    "        seqs, evos, masks, dmats, dmat_masks = seqs.to(device),\\\n",
    "            evos.to(device), masks.to(device), dmats.to(device), dmat_masks.to(device)\n",
    "\n",
    "        test_data = Crops_Dataset(seqs, evos, angs, masks, dmats, dmat_masks,\n",
    "            args.crop_sz, test_stride, args.pad_sz, args.num_dist_bins, device, test=True)\n",
    "\n",
    "        for cidx, (crop, crop_dmat, crop_mask, ij_pos) in enumerate(test_data):\n",
    "            output = model(crop)\n",
    "            \n",
    "            # update the cmap data for the test batch proteins for this crop\n",
    "            test_data.add_pred_crop(output, ij_pos)\n",
    "            \n",
    "            loss = F.cross_entropy(output, crop_dmat, reduction='none')\n",
    "            loss = torch.sum(loss * crop_mask)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_len += torch.sum(crop_mask).item()            \n",
    "            \n",
    "        print(\"batch\", bidx, running_loss, running_len, running_loss/running_len)\n",
    "        \n",
    "        # for each batch, retrieve the predicted and true data and update stats\n",
    "        cmaps, cnts = test_data.get_cmap_data()\n",
    "        dmaps, dmap_masks = test_data.get_dmat_data()\n",
    "        dist_bins = test_data.get_dist_bins()\n",
    "        test_stats.update(cmaps, cnts, dmaps, dmap_masks, pids, lengths, dist_bins)\n",
    "        \n",
    "en = time.time()\n",
    "print(\"test time\", en-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909167a-0ea9-44e7-acb3-81a81c959a9c",
   "metadata": {},
   "source": [
    "## Print the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce240fd-58bf-4009-ac1d-62e4fcf62a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats.print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
